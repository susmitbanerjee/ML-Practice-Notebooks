{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOLzNkyQalAvcq7KJT0bG/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susmitbanerjee/ML-Practice-Notebooks/blob/main/Data%20Pre-Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libs"
      ],
      "metadata": {
        "id": "Ch68dw4vMpEN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyS16vzKMYTm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing dataset"
      ],
      "metadata": {
        "id": "5Lh3Pm2OMnx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"Data.csv\")\n",
        "X = dataset.iloc[: , :-1].values\n",
        "y = dataset.iloc[: , -1].values"
      ],
      "metadata": {
        "id": "A8SYcWFbMecX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "tApzi2ESw69O",
        "outputId": "e6e65e3e-e039-470b-9ea8-797462f244d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "yQfE553Bw8rf",
        "outputId": "9d0fa580-46cb-4b59-a39d-cf1af6a8b14b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy= \"mean\")\n",
        "imputer.fit(X[:, 1:3])\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])"
      ],
      "metadata": {
        "id": "YUX-sGEhSP37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "PiEfkXeswj94",
        "outputId": "629c5e51-9b25-4e4d-883e-13b3c9ac8ea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers= [(\"encoder\", OneHotEncoder(), [0])], remainder=\"passthrough\")\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "pmMEn0pOvd_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "cOurmakCwVuI",
        "outputId": "75c0924b-1446-4440-bf5c-c8e5ffc517b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "GcnfEJk2x5pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "LoV0a8wvyJci",
        "outputId": "4de6df6c-1927-453e-d6d6-82491a122a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "\n",
        "# Identify the categorical data\n",
        "categorical_features = ['Sex', 'Embarked', 'Pclass']\n",
        "\n",
        "\n",
        "# Implement an instance of the ColumnTransformer class\n",
        "ct = ColumnTransformer(transformers= [(\"encoder\", OneHotEncoder(), categorical_features)], remainder=\"passthrough\")\n",
        "\n",
        "# Apply the fit_transform method on the instance of ColumnTransformer\n",
        "X  = ct.fit_transform(dataset)\n",
        "\n",
        "\n",
        "# Convert the output into a NumPy array\n",
        "X = np.array(X)\n",
        "\n",
        "\n",
        "# Use LabelEncoder to encode binary categorical data\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(dataset['Survived'])\n",
        "\n",
        "\n",
        "# Print the updated matrix of features and the dependent variable vector\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "O5ooqD7d8e_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "dataset = pd.read_csv('iris.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = dataset.drop('target', axis =1)\n",
        "y = dataset['target']\n",
        "\n",
        "\n",
        "# Split the dataset into an 80-20 training-test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# Apply feature scaling on the training and test sets\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Print the scaled training and test sets\n",
        "print(X_train)\n",
        "print(X_test)\n"
      ],
      "metadata": {
        "id": "gvaKifV-8gg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Load the Wine Quality Red dataset\n",
        "df = pd.read_csv('winequality-red.csv', delimiter =';')\n",
        "\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('quality', axis = 1)\n",
        "y = df['quality']\n",
        "\n",
        "# Split the dataset into an 80-20 training-test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# Create an instance of the StandardScaler class\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler on the features from the training set and transform it\n",
        "X_train = sc.fit_transform(X_train)\n",
        "\n",
        "\n",
        "# Apply the transform to the test set\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# Print the scaled training and test datasets\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "metadata": {
        "id": "a0UhA5wO7p2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}